{
  "request": {
    "method": "POST",
    "url": "http://localhost:11434/api/generate",
    "headers": {},
    "body": {
      "model": "llama3.2:3b-instruct-fp16",
      "raw": true,
      "prompt": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. You have access to functions, but you should only use them if they are required.\nYou are an expert in composing functions. You are given a question and a set of possible functions.\nBased on the question, you may or may not need to make one function/tool call to achieve the purpose.\n\nIf you decide to invoke any of the function(s), you MUST put it in the format of [func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\nIf you decide to invoke a function, you SHOULD NOT include any other text in the response. besides the function call in the above format.\nFor a boolean parameter, be sure to use `True` or `False` (capitalized) for the value.\n\n\nHere is a list of functions in JSON format that you can invoke.\n\n[\n    {\n        \"name\": \"get_boiling_point_with_metadata\",\n        \"description\": \"Returns the boiling point of a liquid in Celcius or Fahrenheit\",\n        \"parameters\": {\n            \"type\": \"dict\",\n            \"required\": [\"liquid_name\"],\n            \"properties\": {\n                \"liquid_name\": {\n                    \"type\": \"str\",\n                    \"description\": \"The name of the liquid\"\n                },\n                \"celcius\": {\n                    \"type\": \"bool\",\n                    \"description\": \"Whether to return the boiling point in Celcius\",\n                    \"default\": \"True\"\n                }\n            }\n        }\n    }\n]\n\nYou can answer general questions or invoke tools when necessary.\nIn addition to tool calls, you should also augment your responses by using the tool outputs.\nYou are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nCall get_boiling_point_with_metadata tool and answer What is the boiling point of polyjuice?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
      "options": {
        "temperature": 0.0001,
        "top_p": 0.9
      },
      "stream": true
    },
    "endpoint": "/api/generate",
    "model": "llama3.2:3b-instruct-fp16"
  },
  "response": {
    "body": [
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.046199Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "[",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.097228Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "get",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.147575Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "_bo",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.199038Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "iling",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.25106Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "_point",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.302712Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "_with",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.355658Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "_metadata",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.407436Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "(",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.459062Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "liquid",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.511804Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "_name",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.562406Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "='",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.614648Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "poly",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.665414Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "ju",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.71826Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "ice",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.769822Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "',",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.821049Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": " cel",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.872903Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "ci",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.924976Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "us",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:37.976776Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": "=True",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:38.029285Z",
          "done": false,
          "done_reason": null,
          "total_duration": null,
          "load_duration": null,
          "prompt_eval_count": null,
          "prompt_eval_duration": null,
          "eval_count": null,
          "eval_duration": null,
          "response": ")]",
          "thinking": null,
          "context": null
        }
      },
      {
        "__type__": "ollama._types.GenerateResponse",
        "__data__": {
          "model": "llama3.2:3b-instruct-fp16",
          "created_at": "2025-08-01T23:14:38.084154Z",
          "done": true,
          "done_reason": "stop",
          "total_duration": 1782717042,
          "load_duration": 78612834,
          "prompt_eval_count": 375,
          "prompt_eval_duration": 658000000,
          "eval_count": 21,
          "eval_duration": 1044000000,
          "response": "",
          "thinking": null,
          "context": null
        }
      }
    ],
    "is_streaming": true
  }
}
